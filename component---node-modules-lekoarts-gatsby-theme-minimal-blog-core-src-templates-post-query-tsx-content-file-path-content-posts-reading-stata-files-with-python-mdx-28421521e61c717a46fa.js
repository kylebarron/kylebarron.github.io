"use strict";(self.webpackChunkkylebarron_github_io=self.webpackChunkkylebarron_github_io||[]).push([[386],{454:function(e,t,n){function a(e){if(null==e)throw new TypeError("Cannot destructure "+e)}n.d(t,{A:function(){return a}})},1173:function(e,t,n){n.d(t,{p:function(){return h},A:function(){return d}});var a=n(454),r=n(6540),l=n(9894),o=n(6835),i=n(9943),s=n(7715),c=n(7169);var m=e=>{let{post:t}=e;return null};const u=["16px","8px","4px"].map(e=>"rgba(0, 0, 0, 0.1) 0px "+e+" "+e+" 0px");var p=e=>{let{data:{post:t},children:n}=e;return(0,l.Y)(i.A,null,(0,l.Y)(o.DZ,{as:"h1",variant:"styles.h1"},t.title),(0,l.Y)("p",{sx:{color:"secondary",mt:3,a:{color:"secondary"},fontSize:[1,1,2]}},(0,l.Y)("time",null,t.date),t.tags&&(0,l.Y)(r.Fragment,null," — ",(0,l.Y)(s.A,{tags:t.tags})),t.timeToRead&&" — ",t.timeToRead&&(0,l.Y)("span",null,t.timeToRead," min read")),(0,l.Y)("section",{sx:{my:5,".gatsby-resp-image-wrapper":{my:[4,4,5],borderRadius:"4px",boxShadow:u.join(", "),".gatsby-resp-image-image":{borderRadius:"4px"}},variant:"layout.content"}},n),(0,l.Y)(m,{post:t}))};const h=e=>{var t,n,a;let{data:{post:r}}=e;return(0,l.Y)(c.A,{title:r.title,description:r.description?r.description:r.excerpt,image:r.banner?null===(t=r.banner)||void 0===t||null===(n=t.childImageSharp)||void 0===n||null===(a=n.resize)||void 0===a?void 0:a.src:void 0,pathname:r.slug,canonicalUrl:r.canonicalUrl})};function d(e){let t=Object.assign({},((0,a.A)(e),e));return r.createElement(p,t)}},7169:function(e,t,n){var a=n(6540),r=n(4810),l=n(7533);t.A=e=>{let{title:t="",description:n="",pathname:o="",image:i="",children:s=null,canonicalUrl:c=""}=e;const m=(0,l.A)(),{siteTitle:u,siteTitleAlt:p,siteUrl:h,siteDescription:d,siteImage:g,author:y,siteLanguage:f}=m,E={title:t?t+" | "+u:p,description:n||d,url:""+h+(o||""),image:""+h+(i||g)};return a.createElement(a.Fragment,null,a.createElement("html",{lang:f}),a.createElement("title",null,E.title),a.createElement("meta",{name:"description",content:E.description}),a.createElement("meta",{name:"image",content:E.image}),a.createElement("meta",{property:"og:title",content:E.title}),a.createElement("meta",{property:"og:url",content:E.url}),a.createElement("meta",{property:"og:description",content:E.description}),a.createElement("meta",{property:"og:image",content:E.image}),a.createElement("meta",{property:"og:type",content:"website"}),a.createElement("meta",{property:"og:image:alt",content:E.description}),a.createElement("meta",{name:"twitter:card",content:"summary_large_image"}),a.createElement("meta",{name:"twitter:title",content:E.title}),a.createElement("meta",{name:"twitter:url",content:E.url}),a.createElement("meta",{name:"twitter:description",content:E.description}),a.createElement("meta",{name:"twitter:image",content:E.image}),a.createElement("meta",{name:"twitter:image:alt",content:E.description}),a.createElement("meta",{name:"twitter:creator",content:y}),a.createElement("meta",{name:"gatsby-theme",content:"@lekoarts/gatsby-theme-minimal-blog"}),a.createElement("link",{rel:"icon",type:"image/png",sizes:"32x32",href:(0,r.Fe)("/favicon-32x32.png")}),a.createElement("link",{rel:"icon",type:"image/png",sizes:"16x16",href:(0,r.Fe)("/favicon-16x16.png")}),a.createElement("link",{rel:"apple-touch-icon",sizes:"180x180",href:(0,r.Fe)("/apple-touch-icon.png")}),c?a.createElement("link",{rel:"canonical",href:c}):null,s)}},7715:function(e,t,n){var a=n(9894),r=n(6540),l=n(4810),o=n(3601),i=n(2174);t.A=e=>{let{tags:t}=e;const{tagsPath:n,basePath:s}=(0,o.A)();return(0,a.Y)(r.Fragment,null,t.map((e,t)=>(0,a.Y)(r.Fragment,{key:e.slug},!!t&&", ",(0,a.Y)(l.N_,{sx:e=>{var t;return Object.assign({},null===(t=e.styles)||void 0===t?void 0:t.a)},to:(0,i.A)("/"+s+"/"+n+"/"+e.slug)},e.name))))}},9311:function(e,t,n){n.r(t),n.d(t,{Head:function(){return m.p},default:function(){return u}});var a=n(6540),r=n(8453),l=n(2130);function o(){return(o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e}).apply(this,arguments)}var i=(0,a.memo)(function(e){var t=e.children,n=e.math,r=e.block,i=e.errorColor,s=e.renderError,c=e.settings,m=e.as,u=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)t.indexOf(n=l[a])>=0||(r[n]=e[n]);return r}(e,["children","math","block","errorColor","renderError","settings","as"]),p=m||(r?"div":"span"),h=null!=t?t:n,d=(0,a.useState)({innerHtml:""}),g=d[0],y=d[1];return(0,a.useEffect)(function(){try{var e=l.Ay.renderToString(h,o({displayMode:!!r,errorColor:i,throwOnError:!!s},c));y({innerHtml:e})}catch(e){if(!(e instanceof l.Ay.ParseError||e instanceof TypeError))throw e;y(s?{errorElement:s(e)}:{innerHtml:e.message})}},[r,h,i,s,c]),"errorElement"in g?g.errorElement:a.createElement(p,Object.assign({},u,{dangerouslySetInnerHTML:{__html:g.innerHtml}}))});function s(e){const t=Object.assign({p:"p",code:"code",pre:"pre",em:"em",a:"a"},(0,r.RP)(),e.components);return a.createElement(a.Fragment,null,a.createElement(t.p,null,"Stata is fine for the small stuff, but Python is way better for anything\nintensive. However, you'll often have data in Stata's ",a.createElement(t.code,null,".dta")," format that you\nneed to read. This post will detail the nice features available in Python's\nStata import."),"\n",a.createElement(t.p,null,"We'll use the 1978 Automobile Data that comes with Stata. First export this data into a file in your working directory:"),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-stata"},'sysuse auto\nsave "auto.dta", replace\n')),"\n",a.createElement(t.p,null,"Now open up Python. First import Pandas, the module in Python used to work with rectangular data frames."),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"import pandas as pd\n")),"\n",a.createElement(t.p,null,"The most straightforward way to import a Stata file is a single line:"),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"auto = pd.read_stata('auto.dta')\n")),"\n",a.createElement(t.p,null,"This is really simple, and is fine for small files, but with larger files, you often need to finesse your data import.\nImagine you have a 100GB Stata file. For most computers, that's too big to import into memory."),"\n",a.createElement(t.p,null,"First we need to create an ",a.createElement(t.em,null,"iterator"),", which reads the metadata attached to the ",a.createElement(t.code,null,".dta")," file, but importantly doesn't read the data itself yet."),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"itr = pd.read_stata('auto.dta', iterator = True)\n")),"\n",a.createElement(t.p,null,"Now it's possible to read in just a chunk of the data at a time."),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"auto = itr.get_chunk(5)\n")),"\n",a.createElement(t.p,null,"You can also easily loop over the data like so:"),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"itr = pd.read_stata('auto.dta', iterator = True, chunksize = 10)\nfor df in itr:\n    # Program operating on 10 rows of the dataset at a time\n\n")),"\n",a.createElement(t.p,null,"Now without importing the file, we can get the data label, number of observations, number of variables, and the timestamp at which the data were last saved."),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"itr.data_label\nitr.nobs\nitr.nvar\nitr.time_stamp\n")),"\n",a.createElement(t.p,null,"If we want to see the names and labels of the variables, we can use"),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"itr.varlist\nitr.variable_labels()\n")),"\n",a.createElement(t.p,null,"Note that ",a.createElement(t.code,null,"itr.variable_labels()")," returns a dictionary where the keys of the dictionary are the variable names and the values of the dictionary are the variable labels. So we can access the labels with something like:"),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"labels = itr.variable_labels()\n# Gets the label of `mpg`\nlabels['mpg']\n# Gets all keys\nlabels.keys()\n# Gets all values\nlabels.values()\n")),"\n",a.createElement(t.p,null,"If you're working with a large dataset that might run up against memory constraints, you might want to keep in mind exactly how much memory the imported data will take up."),"\n",a.createElement(t.p,null,"You can get a list of the number of bytes each column takes up with the ",a.createElement(t.code,null,"col_sizes")," method:"),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"itr.col_sizes\n")),"\n",a.createElement(t.p,null,"So in ",a.createElement(t.code,null,"auto.dta"),", the first column takes up 18 bytes for each row, while the rest of the columns take up between 1 and 4 bytes."),"\n",a.createElement(t.p,null,"Lets get a better idea of what data types these columns are."),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"itr.dtyplist\nitr.fmtlist\n")),"\n",a.createElement(t.p,null,"The former shows you the data types that will be used in Python upon import and the latter shows the display formats the data had used in Stata (see ",a.createElement(t.a,{href:"https://www.stata.com/help.cgi?format"},a.createElement(t.code,null,"help format")),")."),"\n",a.createElement(t.p,null,"From ",a.createElement(t.code,null,"itr.dtyplist"),", we can see that the first column is a string of length 18, while the rest are types ",a.createElement(t.code,null,"numpy.int8"),", ",a.createElement(t.code,null,"numpy.int16"),", and ",a.createElement(t.code,null,"numpy.float32"),". These data types come from ",a.createElement(t.a,{href:"http://www.numpy.org/"},"Numpy"),", a scientific library that Pandas is based upon, and correspond to Stata's ",a.createElement(t.code,null,"byte"),", ",a.createElement(t.code,null,"int"),", and ",a.createElement(t.code,null,"float"),", respectively (see Stata's ",a.createElement(t.a,{href:"https://www.stata.com/help.cgi?datatypes"},a.createElement(t.code,null,"help data types")),")."),"\n",a.createElement(t.p,null,"The size of the data in memory is almost exactly the number of rows times the sum of the number of bytes needed for each row. I.e. if the number of rows is"),"\n",a.createElement(i,{math:"N"}),"\n",a.createElement(t.p,null,"and the number of bytes each column uses is"),"\n",a.createElement(i,{math:"B_{col}"}),"\n",a.createElement(t.p,null,"then the total memory use of the dataset is"),"\n",a.createElement(i,{math:"N * \\sum_{col} B_{col}"}),"\n",a.createElement(t.p,null,"This can be helpful with understanding how many rows of a file to import at once. Let's say you want to not use more than 1GB of memory at once. If you want to import all columns of ",a.createElement(t.code,null,"auto.dta"),", each row takes up ",a.createElement(t.code,null,"sum(itr.col_sizes)")," = 43 bytes. So the number of rows you can import at a time is"),"\n",a.createElement(i,{math:"1024 MB * \\frac{1024 KB}{1 MB} * \\frac{1024 B}{1 KB} * \\frac{1 \\text{ row}}{43 B} \\approx 25 \\text{ million rows}",block:!0}),"\n",a.createElement(t.p,null,"Obviously with the ",a.createElement(t.code,null,"auto.dta")," dataset we don't need to add restrictions on rows or columns, but in datasets with columns -- especially those with many string columns -- you might not be able to read in your whole dataset at once."))}var c=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,r.RP)(),e.components);return t?a.createElement(t,e,a.createElement(s,e)):s(e)},m=n(1173);function u(e){return a.createElement(m.A,e,a.createElement(c,e))}m.A}}]);
//# sourceMappingURL=component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx-content-file-path-content-posts-reading-stata-files-with-python-mdx-28421521e61c717a46fa.js.map